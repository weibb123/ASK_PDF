{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting text_generation\n",
      "  Obtaining dependency information for text_generation from https://files.pythonhosted.org/packages/5d/80/795be78bc14ab7ddc65620175508791747c13be11fa4848cef96c12012fa/text_generation-0.6.0-py3-none-any.whl.metadata\n",
      "  Downloading text_generation-0.6.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.8 in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from text_generation) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.12 in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from text_generation) (0.16.4)\n",
      "Requirement already satisfied: pydantic<2.0,>=1.10 in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from text_generation) (1.10.12)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from aiohttp<4.0,>=3.8->text_generation) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from aiohttp<4.0,>=3.8->text_generation) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from aiohttp<4.0,>=3.8->text_generation) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from aiohttp<4.0,>=3.8->text_generation) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from aiohttp<4.0,>=3.8->text_generation) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from aiohttp<4.0,>=3.8->text_generation) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from aiohttp<4.0,>=3.8->text_generation) (1.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from huggingface-hub<1.0,>=0.12->text_generation) (3.12.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from huggingface-hub<1.0,>=0.12->text_generation) (2023.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from huggingface-hub<1.0,>=0.12->text_generation) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from huggingface-hub<1.0,>=0.12->text_generation) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from huggingface-hub<1.0,>=0.12->text_generation) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from huggingface-hub<1.0,>=0.12->text_generation) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from huggingface-hub<1.0,>=0.12->text_generation) (23.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.12->text_generation) (0.4.6)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp<4.0,>=3.8->text_generation) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.12->text_generation) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.12->text_generation) (2023.7.22)\n",
      "Downloading text_generation-0.6.0-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: text_generation\n",
      "Successfully installed text_generation-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install text_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import cuda\n",
    "print(cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import os\n",
    "import requests, json\n",
    "from text_generation import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForCausalLM requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForCausalLM\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoModelForCausalLM\n\u001b[1;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mtiiuae/falcon-40b-instruct\u001b[39m\u001b[39m\"\u001b[39m, trust_remote_code\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages\\transformers\\utils\\import_utils.py:1039\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_from_config\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1038\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1039\u001b[0m requires_backends(\u001b[39mcls\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_backends)\n",
      "File \u001b[1;32mc:\\Users\\16178\\anaconda3\\envs\\tf_llm\\lib\\site-packages\\transformers\\utils\\import_utils.py:1018\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[39m# Raise an error for users who might not realize that classes without \"TF\" are torch-only\u001b[39;00m\n\u001b[0;32m   1017\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m backends \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m backends \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_available() \u001b[39mand\u001b[39;00m is_tf_available():\n\u001b[1;32m-> 1018\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(PYTORCH_IMPORT_ERROR_WITH_TF\u001b[39m.\u001b[39mformat(name))\n\u001b[0;32m   1020\u001b[0m \u001b[39m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m backends \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m backends \u001b[39mand\u001b[39;00m is_torch_available() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tf_available():\n",
      "\u001b[1;31mImportError\u001b[0m: \nAutoModelForCausalLM requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForCausalLM\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\"tiiuae/falcon-40b-instruct\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'HF_API_FALCOM_BASE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m client \u001b[39m=\u001b[39m Client(os\u001b[39m.\u001b[39;49menviron[\u001b[39m'\u001b[39;49m\u001b[39mHF_API_FALCOM_BASE\u001b[39;49m\u001b[39m'\u001b[39;49m], headers\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mAuthorization\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBasic \u001b[39m\u001b[39m{\u001b[39;00mhf_api_key\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m}, timeout\u001b[39m=\u001b[39m\u001b[39m120\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\16178\\anaconda3\\envs\\tf_llm\\lib\\os.py:679\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    676\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencodekey(key)]\n\u001b[0;32m    677\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m    678\u001b[0m     \u001b[39m# raise KeyError with the original key value\u001b[39;00m\n\u001b[1;32m--> 679\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    680\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecodevalue(value)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'HF_API_FALCOM_BASE'"
     ]
    }
   ],
   "source": [
    "client = Client(model, headers={'Authorization': f\"Basic {hf_api_key}\"}, timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
